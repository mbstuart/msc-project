{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600171601827",
   "display_name": "Python 3.7.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import path\n",
    "with path.Path('..'):\n",
    "    from services.theme_extractor.preprocessing import ArticlePreprocessJob, ArticlePreprocessor \n",
    "\n",
    "    from services.theme_extractor.wv_model import  WVModelBuilder\n",
    "\n",
    "    from services.theme_extractor.clustering import Clusterer\n",
    "\n",
    "    from services.theme_extractor.keyword_extraction import KeywordExtractor\n",
    "\n",
    "    from services.libs.data_model import ProcessedArticle, Theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dfd2c33b-bdb8-456d-bdff-b1e1ab014309\n"
    }
   ],
   "source": [
    "\n",
    "apj = ArticlePreprocessJob()\n",
    "\n",
    "load_id = apj.get_latest_article_load().id\n",
    "print(load_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10000"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "articles = apj.get_articles_for_load(load_id, max_articles=10000)\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "class APRun:\n",
    "\n",
    "    processed_articles: List[ProcessedArticle]\n",
    "\n",
    "    model: Doc2Vec\n",
    "\n",
    "    labels: List[int]\n",
    "\n",
    "    clusters: List[Theme]\n",
    "\n",
    "    name: str\n",
    "\n",
    "    def __init__(self, name, steps=['lemmatize', 'postag', 'phrasing'], postags=['NOUN', 'ADJ', 'VERB', 'ADV', 'PROPN']):\n",
    "        self.name = name\n",
    "        self.steps = steps;\n",
    "        self.postags = postags;\n",
    "        # self.processed_articles = processed_articles\n",
    "        # self.model = model\n",
    "        # self.labels = labels\n",
    "        # self.clusters = clusters\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "UMAP(a=None, angular_rp_forest=False, b=None, init='spectral',\n     learning_rate=1.0, local_connectivity=1.0, metric='cosine',\n     metric_kwds=None, min_dist=0.1, n_components=100, n_epochs=None,\n     n_neighbors=15, negative_sample_rate=5, random_state=666,\n     repulsion_strength=1.0, set_op_mix_ratio=1.0, spread=1.0,\n     target_metric='categorical', target_metric_kwds=None,\n     target_n_neighbors=-1, target_weight=0.5, transform_queue_size=4.0,\n     transform_seed=42, verbose=True)\nConstruct fuzzy simplicial set\nTue Sep 15 18:44:46 2020 Finding Nearest Neighbors\nTue Sep 15 18:44:46 2020 Building RP forest with 10 trees\nTue Sep 15 18:44:47 2020 NN descent for 13 iterations\n\t 0  /  13\n\t 1  /  13\n\t 2  /  13\n\t 3  /  13\n\t 4  /  13\n\t 5  /  13\nTue Sep 15 18:44:53 2020 Finished Nearest Neighbor Search\nTue Sep 15 18:44:53 2020 Construct embedding\n\tcompleted  0  /  500 epochs\n\tcompleted  50  /  500 epochs\n\tcompleted  100  /  500 epochs\n\tcompleted  150  /  500 epochs\n\tcompleted  200  /  500 epochs\n\tcompleted  250  /  500 epochs\n\tcompleted  300  /  500 epochs\n\tcompleted  350  /  500 epochs\n\tcompleted  400  /  500 epochs\n\tcompleted  450  /  500 epochs\nTue Sep 15 18:46:00 2020 Finished embedding\nExtracting keywords for 831 themes\nUMAP(a=None, angular_rp_forest=False, b=None, init='spectral',\n     learning_rate=1.0, local_connectivity=1.0, metric='cosine',\n     metric_kwds=None, min_dist=0.1, n_components=100, n_epochs=None,\n     n_neighbors=15, negative_sample_rate=5, random_state=666,\n     repulsion_strength=1.0, set_op_mix_ratio=1.0, spread=1.0,\n     target_metric='categorical', target_metric_kwds=None,\n     target_n_neighbors=-1, target_weight=0.5, transform_queue_size=4.0,\n     transform_seed=42, verbose=True)\nConstruct fuzzy simplicial set\nTue Sep 15 19:11:13 2020 Finding Nearest Neighbors\nTue Sep 15 19:11:13 2020 Building RP forest with 10 trees\nTue Sep 15 19:11:13 2020 NN descent for 13 iterations\n\t 0  /  13\n\t 1  /  13\n\t 2  /  13\n\t 3  /  13\n\t 4  /  13\n\t 5  /  13\nTue Sep 15 19:11:19 2020 Finished Nearest Neighbor Search\nTue Sep 15 19:11:19 2020 Construct embedding\n\tcompleted  0  /  500 epochs\n\tcompleted  50  /  500 epochs\n\tcompleted  100  /  500 epochs\n\tcompleted  150  /  500 epochs\n\tcompleted  200  /  500 epochs\n\tcompleted  250  /  500 epochs\n\tcompleted  300  /  500 epochs\n\tcompleted  350  /  500 epochs\n\tcompleted  400  /  500 epochs\n\tcompleted  450  /  500 epochs\nTue Sep 15 19:12:24 2020 Finished embedding\nExtracting keywords for 823 themes\n"
    }
   ],
   "source": [
    "def run_ap_options(run_options: APRun):\n",
    "\n",
    "    load_id = run_options.name\n",
    "\n",
    "    ap = ArticlePreprocessor(steps=run_options.steps, allowed_postags=run_options.postags)\n",
    "    processed_articles = ap.preprocess_articles(articles, load_id)\n",
    "\n",
    "    model_builder = WVModelBuilder()\n",
    "\n",
    "    model = model_builder.build_wv_model(processed_articles)\n",
    "\n",
    "    labels = Clusterer(model, processed_articles, load_id).create_mapping(min_cluster_size=3, cluster_selection_epsilon=0.1)\n",
    "    \n",
    "    clusters = KeywordExtractor(model).create_themes(load_id, processed_articles, labels)\n",
    "\n",
    "    return processed_articles, model, labels, clusters\n",
    "\n",
    "def calculate_runs():\n",
    "\n",
    "    runs: List[APRun] = [\n",
    "        APRun('run_with_all'),\n",
    "        APRun('run_with_no_phrasing', steps=['postag', 'lemmatize'])\n",
    "    ]\n",
    "\n",
    "    for run in runs:\n",
    "        processed_articles, model, labels, clusters = run_ap_options(run);\n",
    "        run.processed_articles = processed_articles\n",
    "        run.model = model\n",
    "        run.labels = labels\n",
    "        run.clusters = clusters\n",
    "\n",
    "    return runs\n",
    "    \n",
    "ap_runs = calculate_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Blue Origin Musk spacex\n['Nasa astronaut', 'Musk spacex', 'Origin Musk spacex', 'astronaut US', 'Musk spacex build new', 'capsule dock', 'spaceflight suddenly resign day', 'crew capsule dock International', 'spaceflight suddenly']\nthrash Cologne Frauen Bundesliga\n['Cologne Frauen Bundesliga', 'Coventry beat', 'Frauen Bundesliga', 'thrash Cologne', 'Wolfsburg thrash', 'Wolfsburg thrash Cologne Frauen', 'Wolfsburg thrash Cologne', 'thrash Cologne Frauen', 'beat Ipswich']\nfury Wilder II\n['fury Wilder', 'Anthony Joshua would underdog', 'Joshua would underdog', 'would underdog', 'Joshua would underdog Tyson', 'underdog Tyson Fury', 'would underdog Tyson', 'underdog Tyson Fury say', 'Wilder II fighter']\nRory McIlroy produce shot\n['Thomas lead clutch', 'hold Rory McIlroy', 'Hatton hold Rory McIlroy', 'Rory McIlroy', 'Thomas lead clutch top', 'lead clutch', 'Hatton hold Rory', 'produce shot', 'hold nerve secure victory']\nteammate give wither\n['Jordan teammate', 'bree sorry LeBron', 'LeBron James lead backlash', 'attack silence', 'Jordan teammate give wither', 'teammate give', 'kicker Rohrwasser deny tattoo', 'trash say tell', 'kicker Rohrwasser deny']\n"
    }
   ],
   "source": [
    "for i in [1, 11, 21, 31, 41]:\n",
    "    cluster = ap_runs[1].clusters[i]\n",
    "    print(cluster.name)\n",
    "    print(cluster.theme_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}