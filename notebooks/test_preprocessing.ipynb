{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.5 64-bit ('base': conda)",
   "display_name": "Python 3.7.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "00c13f55ba049f4e591e16c55112044268b965477979f20629110d152507d31b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import path\n",
    "with path.Path('..'):\n",
    "    from services.theme_extractor.preprocessing import ArticlePreprocessJob, ArticlePreprocessor \n",
    "\n",
    "    from services.theme_extractor.wv_model import  WVModelBuilder\n",
    "\n",
    "    from services.theme_extractor.clustering import Clusterer\n",
    "\n",
    "    from services.theme_extractor.keyword_extraction import KeywordExtractor\n",
    "\n",
    "    from services.libs.data_model import ProcessedArticle, Theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "467130b3-fe75-4f1f-b2fa-4757e15f11fd\n"
    }
   ],
   "source": [
    "\n",
    "apj = ArticlePreprocessJob()\n",
    "\n",
    "load_id = apj.get_latest_article_load().id\n",
    "print(load_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10000"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "articles = apj.get_articles_for_load(load_id, max_articles=10000)\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from gensim.models import Doc2Vec\n",
    "import numpy as np\n",
    "\n",
    "class APRun:\n",
    "\n",
    "    processed_articles: List[ProcessedArticle]\n",
    "\n",
    "    model: Doc2Vec\n",
    "\n",
    "    labels: np.array\n",
    "\n",
    "    clusters: List[Theme]\n",
    "\n",
    "    name: str\n",
    "\n",
    "    def __init__(self, name, steps=['lemmatize', 'postag', 'phrasing'], postags=['NOUN', 'ADJ', 'VERB', 'ADV', 'PROPN']):\n",
    "        self.name = name\n",
    "        self.steps = steps;\n",
    "        self.postags = postags;\n",
    "        # self.processed_articles = processed_articles\n",
    "        # self.model = model\n",
    "        # self.labels = labels\n",
    "        # self.clusters = clusters\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "UMAP(a=None, angular_rp_forest=False, b=None, init=&#39;spectral&#39;,\n     learning_rate=1.0, local_connectivity=1.0, metric=&#39;cosine&#39;,\n     metric_kwds=None, min_dist=0.1, n_components=100, n_epochs=None,\n     n_neighbors=15, negative_sample_rate=5, random_state=666,\n     repulsion_strength=1.0, set_op_mix_ratio=1.0, spread=1.0,\n     target_metric=&#39;categorical&#39;, target_metric_kwds=None,\n     target_n_neighbors=-1, target_weight=0.5, transform_queue_size=4.0,\n     transform_seed=42, verbose=True)\nConstruct fuzzy simplicial set\nSun Oct  4 12:45:01 2020 Finding Nearest Neighbors\nSun Oct  4 12:45:01 2020 Building RP forest with 10 trees\nSun Oct  4 12:45:03 2020 NN descent for 13 iterations\n\t 0  /  13\n\t 1  /  13\n\t 2  /  13\n\t 3  /  13\n\t 4  /  13\nSun Oct  4 12:45:10 2020 Finished Nearest Neighbor Search\nSun Oct  4 12:45:15 2020 Construct embedding\n\tcompleted  0  /  500 epochs\n\tcompleted  50  /  500 epochs\n\tcompleted  100  /  500 epochs\n\tcompleted  150  /  500 epochs\n\tcompleted  200  /  500 epochs\n\tcompleted  250  /  500 epochs\n\tcompleted  300  /  500 epochs\n\tcompleted  350  /  500 epochs\n\tcompleted  400  /  500 epochs\n\tcompleted  450  /  500 epochs\nSun Oct  4 12:46:40 2020 Finished embedding\nExtracting keywords for 756 themes\nUMAP(a=None, angular_rp_forest=False, b=None, init=&#39;spectral&#39;,\n     learning_rate=1.0, local_connectivity=1.0, metric=&#39;cosine&#39;,\n     metric_kwds=None, min_dist=0.1, n_components=100, n_epochs=None,\n     n_neighbors=15, negative_sample_rate=5, random_state=666,\n     repulsion_strength=1.0, set_op_mix_ratio=1.0, spread=1.0,\n     target_metric=&#39;categorical&#39;, target_metric_kwds=None,\n     target_n_neighbors=-1, target_weight=0.5, transform_queue_size=4.0,\n     transform_seed=42, verbose=True)\nConstruct fuzzy simplicial set\nSun Oct  4 13:17:05 2020 Finding Nearest Neighbors\nSun Oct  4 13:17:05 2020 Building RP forest with 10 trees\nSun Oct  4 13:17:06 2020 NN descent for 13 iterations\n\t 0  /  13\n\t 1  /  13\n\t 2  /  13\n\t 3  /  13\n\t 4  /  13\nSun Oct  4 13:17:12 2020 Finished Nearest Neighbor Search\nSun Oct  4 13:17:12 2020 Construct embedding\n\tcompleted  0  /  500 epochs\n\tcompleted  50  /  500 epochs\n\tcompleted  100  /  500 epochs\n\tcompleted  150  /  500 epochs\n\tcompleted  200  /  500 epochs\n\tcompleted  250  /  500 epochs\n\tcompleted  300  /  500 epochs\n\tcompleted  350  /  500 epochs\n\tcompleted  400  /  500 epochs\n\tcompleted  450  /  500 epochs\nSun Oct  4 13:18:23 2020 Finished embedding\nExtracting keywords for 830 themes\nUMAP(a=None, angular_rp_forest=False, b=None, init=&#39;spectral&#39;,\n     learning_rate=1.0, local_connectivity=1.0, metric=&#39;cosine&#39;,\n     metric_kwds=None, min_dist=0.1, n_components=100, n_epochs=None,\n     n_neighbors=15, negative_sample_rate=5, random_state=666,\n     repulsion_strength=1.0, set_op_mix_ratio=1.0, spread=1.0,\n     target_metric=&#39;categorical&#39;, target_metric_kwds=None,\n     target_n_neighbors=-1, target_weight=0.5, transform_queue_size=4.0,\n     transform_seed=42, verbose=True)\nConstruct fuzzy simplicial set\nSun Oct  4 14:01:00 2020 Finding Nearest Neighbors\nSun Oct  4 14:01:00 2020 Building RP forest with 10 trees\nSun Oct  4 14:01:00 2020 NN descent for 13 iterations\n\t 0  /  13\n\t 1  /  13\n\t 2  /  13\n\t 3  /  13\n\t 4  /  13\n\t 5  /  13\nSun Oct  4 14:01:07 2020 Finished Nearest Neighbor Search\nSun Oct  4 14:01:07 2020 Construct embedding\n\tcompleted  0  /  500 epochs\n\tcompleted  50  /  500 epochs\n\tcompleted  100  /  500 epochs\n\tcompleted  150  /  500 epochs\n\tcompleted  200  /  500 epochs\n\tcompleted  250  /  500 epochs\n\tcompleted  300  /  500 epochs\n\tcompleted  350  /  500 epochs\n\tcompleted  400  /  500 epochs\n\tcompleted  450  /  500 epochs\nSun Oct  4 14:02:14 2020 Finished embedding\nExtracting keywords for 791 themes\nUMAP(a=None, angular_rp_forest=False, b=None, init=&#39;spectral&#39;,\n     learning_rate=1.0, local_connectivity=1.0, metric=&#39;cosine&#39;,\n     metric_kwds=None, min_dist=0.1, n_components=100, n_epochs=None,\n     n_neighbors=15, negative_sample_rate=5, random_state=666,\n     repulsion_strength=1.0, set_op_mix_ratio=1.0, spread=1.0,\n     target_metric=&#39;categorical&#39;, target_metric_kwds=None,\n     target_n_neighbors=-1, target_weight=0.5, transform_queue_size=4.0,\n     transform_seed=42, verbose=True)\nConstruct fuzzy simplicial set\nSun Oct  4 14:29:45 2020 Finding Nearest Neighbors\nSun Oct  4 14:29:45 2020 Building RP forest with 10 trees\nSun Oct  4 14:29:46 2020 NN descent for 13 iterations\n\t 0  /  13\n\t 1  /  13\n\t 2  /  13\n\t 3  /  13\n\t 4  /  13\nSun Oct  4 14:29:51 2020 Finished Nearest Neighbor Search\nSun Oct  4 14:29:52 2020 Construct embedding\n\tcompleted  0  /  500 epochs\n\tcompleted  50  /  500 epochs\n\tcompleted  100  /  500 epochs\n\tcompleted  150  /  500 epochs\n\tcompleted  200  /  500 epochs\n\tcompleted  250  /  500 epochs\n\tcompleted  300  /  500 epochs\n\tcompleted  350  /  500 epochs\n\tcompleted  400  /  500 epochs\n\tcompleted  450  /  500 epochs\nSun Oct  4 14:30:59 2020 Finished embedding\nExtracting keywords for 766 themes\nUMAP(a=None, angular_rp_forest=False, b=None, init=&#39;spectral&#39;,\n     learning_rate=1.0, local_connectivity=1.0, metric=&#39;cosine&#39;,\n     metric_kwds=None, min_dist=0.1, n_components=100, n_epochs=None,\n     n_neighbors=15, negative_sample_rate=5, random_state=666,\n     repulsion_strength=1.0, set_op_mix_ratio=1.0, spread=1.0,\n     target_metric=&#39;categorical&#39;, target_metric_kwds=None,\n     target_n_neighbors=-1, target_weight=0.5, transform_queue_size=4.0,\n     transform_seed=42, verbose=True)\nConstruct fuzzy simplicial set\nSun Oct  4 15:00:23 2020 Finding Nearest Neighbors\nSun Oct  4 15:00:23 2020 Building RP forest with 10 trees\nSun Oct  4 15:00:24 2020 NN descent for 13 iterations\n\t 0  /  13\n\t 1  /  13\n\t 2  /  13\n\t 3  /  13\n\t 4  /  13\nSun Oct  4 15:00:33 2020 Finished Nearest Neighbor Search\nSun Oct  4 15:00:33 2020 Construct embedding\n\tcompleted  0  /  500 epochs\n\tcompleted  50  /  500 epochs\n\tcompleted  100  /  500 epochs\n\tcompleted  150  /  500 epochs\n\tcompleted  200  /  500 epochs\n\tcompleted  250  /  500 epochs\n\tcompleted  300  /  500 epochs\n\tcompleted  350  /  500 epochs\n\tcompleted  400  /  500 epochs\n\tcompleted  450  /  500 epochs\nSun Oct  4 15:02:19 2020 Finished embedding\nExtracting keywords for 806 themes\n"
    }
   ],
   "source": [
    "def run_ap_options(run_options: APRun):\n",
    "\n",
    "    load_id = run_options.name\n",
    "\n",
    "    ap = ArticlePreprocessor(steps=run_options.steps, allowed_postags=run_options.postags)\n",
    "    processed_articles = ap.preprocess_articles(articles, load_id)\n",
    "\n",
    "    model_builder = WVModelBuilder()\n",
    "\n",
    "    model = model_builder.build_wv_model(processed_articles)\n",
    "\n",
    "    labels = Clusterer(model, processed_articles, load_id).create_mapping(min_cluster_size=3, cluster_selection_epsilon=0.1)\n",
    "    \n",
    "    clusters = KeywordExtractor(model).create_themes(load_id, processed_articles, labels)\n",
    "\n",
    "    return processed_articles, model, labels, clusters\n",
    "\n",
    "def calculate_runs():\n",
    "\n",
    "    runs: List[APRun] = [\n",
    "        APRun('run_with_all'),\n",
    "        APRun('run_with_none', steps=[]),\n",
    "        APRun('run_with_no_phrasing', steps=['postag', 'lemmatize']),\n",
    "        APRun('run_with_no_lemmatize', steps=['postag', 'phrasing']),\n",
    "        APRun('run_with_no_postag', steps=['lemmatize', 'phrasing'])\n",
    "\n",
    "    ]\n",
    "\n",
    "    for run in runs:\n",
    "        processed_articles, model, labels, clusters = run_ap_options(run);\n",
    "        run.processed_articles = processed_articles\n",
    "        run.model = model\n",
    "        run.labels = labels\n",
    "        run.clusters = clusters\n",
    " \n",
    "    return runs\n",
    "    \n",
    "ap_runs = calculate_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\nnew coronavirus case fall low level\n13\n[&#39;volatile former ambassador warn&#39;, &#39;british musical&#39;, &#39;former ambassador&#39;, &#39;ambassador warn&#39;, &#39;volatile former ambassador&#39;, &#39;tory rebellion&#39;, &#39;death toll exceed&#39;, &#39;long await oversight board&#39;, &#39;face big&#39;]\n13\nfile bankruptcy\n5\n[&#39;England Wales MPs urge&#39;, &#39;test positive coronaviru&#39;, &#39;dfid merger&#39;, &#39;polo shirt&#39;, &#39;visit ban&#39;, &#39;jogger polo shirt&#39;, &#39;couple test positive coronaviru&#39;, &#39;Berlin couple test positive coronaviru&#39;, &#39;reputation dfid&#39;]\n20\nreport record week\n9\n[&#39;will consider strike action&#39;, &#39;consider strike action&#39;, &#39;postal chief oust&#39;, &#39;chief oust brother&#39;, &#39;boost eat help&#39;, &#39;postal chief oust brother&#39;, &#39;publisher hit back&#39;, &#39;back office plan&#39;, &#39;court file&#39;]\n499\nbotched ecce homo\n3\n[&#39;institute say restoration&#39;, &#39;humanoid restoration&#39;, &#39;shock reveal depiction&#39;, &#39;vividness richness&#39;, &#39;say restoration&#39;, &#39;homo also know&#39;, &#39;wanton institutional vandalism preet&#39;, &#39;nightmarish other&#39;, &#39;christ sheep paint&#39;]\n599\npollutant diesel\n3\n[&#39;sydney suburb moorebank bankstown&#39;, &#39;norton liverpool lidcombe&#39;, &#39;lithium ion&#39;, &#39;sydney suburb moorebank&#39;, &#39;rooftop bar grill&#39;, &#39;driver also&#39;, &#39;bring total cost low energy&#39;, &#39;area casey&#39;, &#39;such tesla&#39;]\n"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(ap_runs[0].labels)\n",
    "\n",
    "for i in [1, 14, 21, 500, 600]:\n",
    "    cluster = ap_runs[0].clusters[i]\n",
    "    print(cluster.id)\n",
    "    print(cluster.name)\n",
    "    print(counts[cluster.id])\n",
    "    print(cluster.theme_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(set1: np.array, set2: np.array):\n",
    "    return len(np.intersect1d(set1, set2)) / len(np.union1d(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThemeTarget:\n",
    "\n",
    "    def __init__(self, label: int, name: str):\n",
    "        self.label = label\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "targets: List[ThemeTarget] = [\n",
    "    ThemeTarget(0, 'Grenfell'),\n",
    "    ThemeTarget(13, 'Coronavirus students'),\n",
    "    ThemeTarget(20, 'Shoes'),\n",
    "    ThemeTarget(399, 'Suleimani'),\n",
    "    ThemeTarget(599, 'Labour Manifesto'),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1, 0, 1, 0, 0 is a match!\n41, 18, 0, 1, 26 is a match!\n99, 192, 125, 272, 178 is a match!\n203, 369, 337, 367, 280 is a match!\n356, 11, 57, 87, 233 is a match!\n"
    }
   ],
   "source": [
    "## find targets which match\n",
    "\n",
    "def jacc_match(base_articles, mapping_articles_idx):\n",
    "    clusters = []\n",
    "    for i, run in enumerate(ap_runs):\n",
    "        cluster_match = Counter(run.labels[mapping_articles_idx]).most_common();\n",
    "        main_cluster = cluster_match[0][0]\n",
    "\n",
    "\n",
    "        theme_articles = [a.id for a in np.array(articles)[np.where(run.labels == main_cluster)]]\n",
    "        clusters.append(str(main_cluster))\n",
    "        if jaccard(theme_articles, base_articles) < .9:\n",
    "            return False\n",
    "    return clusters\n",
    "\n",
    "matching_labels = []\n",
    "\n",
    "for label_id in range(0, max(ap_runs[0].labels)):\n",
    "    mapping = ap_runs[0].labels\n",
    "    mapping_articles_idx = np.where(mapping == label_id)\n",
    "    base_articles = [a.id for a in np.array(articles)[mapping_articles_idx]]\n",
    "\n",
    "    match = jacc_match(base_articles, mapping_articles_idx)\n",
    "\n",
    "    if match:\n",
    "        print(\"{} is a match!\".format(\", \".join(match)))\n",
    "        matching_labels.append(match)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Chess: David Howell and Michael Adams battle for England No 1 spot in Torquay\nChess: Magnus Carlsen at peak but faces Saturday test against Wesley So\nChess: Michael Adams wins seven as England&#39;s top players battle lockdown\nChess: Kasparov and Carlsen undone by internet glitches following 55-move draw\nChess: Garry Kasparov and Magnus Carlsen draw in historic encounter\nChess: Russia and India&#39;s shared Olympiad gold sparks wave of criticism\nChess: Six-way tie at Hastings as tournament battles richer rivals\nIndia awarded chess gold with Russia after server outage leads to reprieve\nChess: Garry Kasparov and Magnus Carlsen to meet for first time in 16 years\nChess: Carlsen fights back from brink to overcome Nakamura in 38-game epic\n\n\nRevealed: ex-MPs use parliament access passes over 2,500 times in a year\nPeers call on Jenrick  to explain opposition to smoke-free zones\nTory peer accused of breaching ministerial code with Uganda deals\nRobert Jenrick says he regrets dining with donor before planning decision\nMPs ask Robert Jenrick long list of questions about £1bn land deal\nRevealed: Developers PM backed when London mayor give almost £1m to Tories\nPriti Patel backs Robert Jenrick over &#39;cash for favours&#39; scandal\nRobert Jenrick admits Israeli billionaire he had meeting with is family friend\nLabour reports Robert Jenrick to parliamentary watchdog\nJenrick affair exposes a financialised planning system\n\n\nAustralian universities cautious on government plan to bring forward funding to help with Covid crisis\nAlmost 500 more university jobs to go at ANU and UNSW as Covid cuts bite\nLabor accuses Australian universities of being &#39;in cahoots&#39; with government over funding changes\nUniversity funding changes: Centre Alliance signals it may back Coalition bill\nAustralian universities walk back their criticism of higher education changes\nRegional universities urge Coalition funding changes to be passed as Senate inquiry approved\nSenate crossbenchers join push to send Coalition’s uni funding bill to inquiry\nDan Tehan forced to correct &#39;sloppy or mischievous&#39; error in university statistics\nAustralian university education predicted to decline amid job cuts and ballooning enrolments\nUniversity fee rises: Nationals&#39; deal for psychology and social work to cost other students\n\n\nGovernment briefing to allay universities&#39; fears over foreign veto laws adds to uncertainty\nForeign veto laws could affect tens of thousands of research projects, Australian universities warn\nCoalition plans to lure big foreign companies to Australia with tax breaks\nLabor wants to use Coalition&#39;s proposed foreign veto powers to unwind Darwin port sale\nAustralian universities &#39;blindsided&#39; by government seeking powers to cancel global agreements\n&#39;It is about China&#39;: foreign relations bill lambasted as &#39;complete overkill&#39; on Q+A\nCoalition plan to end global deals by universities smacks of ‘McCarthyist campaign’, says Labor\nPort of Darwin ‘critical’ in new commonwealth power to veto deals with foreign governments, Albanese says\nAustralian researchers condemn &#39;groundless vilification&#39; of their work with China\nCoalition urged by backbench to launch inquiry into foreign interference in Australian academia\n\n\nUK accused of failing to promote minority languages\nScottish politicians call for urgent action to stop Gaelic dying out\nScots Gaelic could die out within a decade, study finds\n\n\n"
    }
   ],
   "source": [
    "for label_ids in matching_labels:\n",
    "    base_articles = [a.title for a in np.array(articles)[np.where(ap_runs[0].labels == int(label_ids[0]))]]\n",
    "    print(\"\\n\".join([art for i, art in enumerate(base_articles) if i < 10]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Inquest into suicide of gambling addict will explore if UK state failed him\n[&#39;inquest&#39;, &#39;suicide&#39;, &#39;gambling&#39;, &#39;addict&#39;, &#39;will&#39;, &#39;explore&#39;, &#39;UK&#39;, &#39;state&#39;, &#39;fail&#39;]\n"
    }
   ],
   "source": [
    "print(articles[100].title)\n",
    "\n",
    "print(ap_runs[0].processed_articles[100].title_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "targets: List[ThemeTarget] = [\n",
    "    ThemeTarget(0, 'Grenfell'),\n",
    "    ThemeTarget(13, 'Coronavirus students'),\n",
    "    ThemeTarget(20, 'Shoes'),\n",
    "    ThemeTarget(399, 'Suleimani'),\n",
    "    ThemeTarget(599, 'Labour Manifesto'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_with_all</th>\n      <th>run_with_none</th>\n      <th>run_with_no_phrasing</th>\n      <th>run_with_no_lemmatize</th>\n      <th>run_with_no_postag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>chess Garry</td>\n      <td>chess gold with</td>\n      <td>chess Garry Kasparov</td>\n      <td>Chess Adams stirs</td>\n      <td>15-match winning</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>chess Hou</td>\n      <td>awarded chess</td>\n      <td>chess Hou Yifan</td>\n      <td>India awarded chess</td>\n      <td>tops fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>chess Garry Kasparov</td>\n      <td>awarded chess gold with</td>\n      <td>chess England</td>\n      <td>awarded chess</td>\n      <td>as tournament</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>chess Michael Adams</td>\n      <td>15-match winning</td>\n      <td>chess Hou</td>\n      <td>Magnus Carlsen</td>\n      <td>-PRON- 15-match winning</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>chess Hou Yifan</td>\n      <td>mate in</td>\n      <td>chess Garry</td>\n      <td>Carlsen misses mate over-50s</td>\n      <td>mate in</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>chess Kasparov</td>\n      <td>India awarded chess</td>\n      <td>chess Kasparov</td>\n      <td>Kasparov Magnus Carlsen</td>\n      <td>rout Caruana and tops</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Magnus Carlsen</td>\n      <td>and tops fantasy</td>\n      <td>chess David Howell Michael</td>\n      <td>Adams stirs</td>\n      <td>, no 1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Garry Kasparov Magnus Carlsen</td>\n      <td>prize despite bizarre four</td>\n      <td>chess Adams stir</td>\n      <td>alias Biel</td>\n      <td>Hou Yifan , no 1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Kasparov Magnus Carlsen</td>\n      <td>chess gold</td>\n      <td>Garry Kasparov Magnus Carlsen</td>\n      <td>Chess Carlsen routs</td>\n      <td>and tops fantasy football league</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>chess Carlsen rout</td>\n      <td>prize despite bizarre</td>\n      <td>award chess</td>\n      <td>Carlsen routs</td>\n      <td>prize despite bizarre</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_with_all</th>\n      <th>run_with_none</th>\n      <th>run_with_no_phrasing</th>\n      <th>run_with_no_lemmatize</th>\n      <th>run_with_no_postag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>smoke free</td>\n      <td>passes over 2,500 times</td>\n      <td>grow pressure</td>\n      <td>Marxists doe</td>\n      <td>from developer</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>give almost tory</td>\n      <td>, Tory donations</td>\n      <td>Desmond former porn baron</td>\n      <td>Jenrick media mogul</td>\n      <td>after fresh Desmond revelation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Marxists doe</td>\n      <td>for favours</td>\n      <td>want give Marxists doe</td>\n      <td>want give Marxists doe texts</td>\n      <td>fund from developer</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jenrick face question</td>\n      <td>2,500 times</td>\n      <td>Desmond Jenrick</td>\n      <td>Jenrick says regrets</td>\n      <td>donor before planning decision</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>peer accuse breach</td>\n      <td>suggests voters could raise</td>\n      <td>swift return</td>\n      <td>pressure resign donor</td>\n      <td>with Uganda deal</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>peer accuse breach ministerial code</td>\n      <td>Robert Jenrick faces questions</td>\n      <td>smoke free</td>\n      <td>doe texts Desmond</td>\n      <td>Minister suggest voter could</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1bn housing</td>\n      <td>swift return</td>\n      <td>israeli billionaire meet</td>\n      <td>Robert Jenrick says regrets</td>\n      <td>long list of</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Jenrick cash favour scandal</td>\n      <td>planning row</td>\n      <td>swift return lockdown</td>\n      <td>planning row</td>\n      <td>under grow pressure</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>could raise</td>\n      <td>do n't want to</td>\n      <td>Jenrick grow pressure</td>\n      <td>Marxists doe texts Desmond</td>\n      <td>-PRON- do not want to give</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>give Marxists doe</td>\n      <td>faces questions over</td>\n      <td>meet israeli mining heir</td>\n      <td>Jenrick long list questions</td>\n      <td>£ 1bn land deal</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_with_all</th>\n      <th>run_with_none</th>\n      <th>run_with_no_phrasing</th>\n      <th>run_with_no_lemmatize</th>\n      <th>run_with_no_postag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>australian university walk back</td>\n      <td>ballooning enrolments</td>\n      <td>ballooning enrolment</td>\n      <td>ballooning enrolments</td>\n      <td>criticism of high education</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>australian university cahoot</td>\n      <td>and ballooning enrolments</td>\n      <td>unit monitor enrolment</td>\n      <td>unit monitor enrolments</td>\n      <td>university and</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>australian university plead</td>\n      <td>of university</td>\n      <td>monitor enrolment</td>\n      <td>walk back criticism higher education</td>\n      <td>back -PRON- criticism of high education</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ballooning enrolment</td>\n      <td>’s uni</td>\n      <td>cut ballooning enrolment</td>\n      <td>university statistics</td>\n      <td>effect of university</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>australian university walk back criticism</td>\n      <td>to monitor enrolments</td>\n      <td>university urge coalition</td>\n      <td>universities cahoots</td>\n      <td>-PRON- criticism of high education</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>australian university cahoot government</td>\n      <td>cuts and ballooning enrolments</td>\n      <td>australian university plead</td>\n      <td>decline job cuts ballooning enrolments</td>\n      <td>modelling on effect of university</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>unit monitor enrolment</td>\n      <td>courses , but fall</td>\n      <td>university plead fee rise</td>\n      <td>Universities blindsided</td>\n      <td>Sydney university</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>more university job</td>\n      <td>unit to monitor enrolments</td>\n      <td>almost half australian phd</td>\n      <td>mischievous error university</td>\n      <td>on effect of university fee</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>accuse australian university cahoot government</td>\n      <td>universities of</td>\n      <td>australian phd</td>\n      <td>merge faculties</td>\n      <td>university warn</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>struggle university</td>\n      <td>hikes , official reveals</td>\n      <td>Sydney university ask staff</td>\n      <td>criticism higher education</td>\n      <td>australian university of</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_with_all</th>\n      <th>run_with_none</th>\n      <th>run_with_no_phrasing</th>\n      <th>run_with_no_lemmatize</th>\n      <th>run_with_no_postag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>project australian university</td>\n      <td>universities ' fears over</td>\n      <td>blindside government</td>\n      <td>universities fears</td>\n      <td>foreign government ,</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ten thousand research project australian university</td>\n      <td>universities ' blindsided '</td>\n      <td>allay university fear foreign</td>\n      <td>universities smacks McCarthyist</td>\n      <td>australian university ' blindside</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>groundless vilification</td>\n      <td>universities ' blindsided</td>\n      <td>university smack McCarthyist campaign</td>\n      <td>briefing allay universities fears</td>\n      <td>australian university ' blindside '</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>foreign government Albanese say</td>\n      <td>briefing to allay universities</td>\n      <td>foreign government Albanese</td>\n      <td>unwind Darwin port sale</td>\n      <td>, australian university</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>research project australian university</td>\n      <td>to allay universities</td>\n      <td>vilification work</td>\n      <td>universities blindsided</td>\n      <td>foreign government , Albanese say</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>smack McCarthyist campaign say</td>\n      <td>by universities</td>\n      <td>global deal university smack</td>\n      <td>universities smacks McCarthyist campaign</td>\n      <td>project , australian university</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>australian university blindside government seek</td>\n      <td>to unwind Darwin port</td>\n      <td>university blindside government</td>\n      <td>foreign interference Australian academia</td>\n      <td>foreign government , Albanese</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>researcher condemn groundless</td>\n      <td>universities smacks of ‘</td>\n      <td>blindside government seek</td>\n      <td>allay universities fears</td>\n      <td>research project , australian university</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>deal university smack</td>\n      <td>deals by universities</td>\n      <td>override state pact foreign</td>\n      <td>unwind Darwin port</td>\n      <td>foreign interference in</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>foreign government Albanese</td>\n      <td>unwind Darwin port sale</td>\n      <td>foreign government Albanese say</td>\n      <td>universities blindsided government seeking</td>\n      <td>australian university '</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_with_all</th>\n      <th>run_with_none</th>\n      <th>run_with_no_phrasing</th>\n      <th>run_with_no_lemmatize</th>\n      <th>run_with_no_postag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>put gaelic</td>\n      <td>gaelic committee</td>\n      <td>gaelic job</td>\n      <td>life gaelic</td>\n      <td>, a gaelic</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gaelic give precedence parity</td>\n      <td>the gaelic</td>\n      <td>say gaelic</td>\n      <td>gaelic said</td>\n      <td>of gaelic be</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>trend put gaelic</td>\n      <td>gaelic .</td>\n      <td>charge promote gaelic</td>\n      <td>said gaelic</td>\n      <td>. gaelic</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gaelic say</td>\n      <td>as a gaelic</td>\n      <td>last week gaelic</td>\n      <td>gaelic inextricably linked</td>\n      <td>, \" -PRON- say . gaelic</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>say gaelic give precedence</td>\n      <td>“ the gaelic</td>\n      <td>put gaelic</td>\n      <td>habitual gaelic</td>\n      <td>the gaelic</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>siar increase gaelic</td>\n      <td>, a gaelic</td>\n      <td>job future gaelic</td>\n      <td>bòrd gàidhlig official gaelic</td>\n      <td>may assume that the gaelic</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>gaelic figure put</td>\n      <td>gaelic in</td>\n      <td>gaelic fall</td>\n      <td>however gaelic</td>\n      <td>of gaelic</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>may assume gaelic</td>\n      <td>decline of gaelic .</td>\n      <td>gaelic job future gaelic</td>\n      <td>manx gaelic isle man</td>\n      <td>by gaelic</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>say gaelic</td>\n      <td>. gaelic</td>\n      <td>gaelic job future</td>\n      <td>gaelic isle man</td>\n      <td>. \" the gaelic</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>invest gaelic</td>\n      <td>gaelic in the</td>\n      <td>protect gaelic</td>\n      <td>investing gaelic</td>\n      <td>gaelic ,</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "for label_ids in matching_labels:\n",
    "\n",
    "    for i, run in enumerate(ap_runs):\n",
    "        \n",
    "        main_cluster = int(label_ids[i])\n",
    "\n",
    "        theme_articles = [a.id for a in np.array(articles)[np.where(run.labels == main_cluster)]]\n",
    "        data[run.name] = [[c.name] + c.theme_words for c in run.clusters if c.id == main_cluster][0]\n",
    "\n",
    "    display(HTML(pd.DataFrame(data).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   run_with_all  run_with_none  run_with_no_phrasing  run_with_no_lemmatize  \\\n0      1.000000       0.535477              0.619525               0.613201   \n1      0.535477       1.000000              0.540951               0.536786   \n2      0.619525       0.540951              1.000000               0.581408   \n3      0.613201       0.536786              0.581408               1.000000   \n4      0.550287       0.545302              0.534625               0.540062   \n\n   run_with_no_postag  \n0            0.550287  \n1            0.545302  \n2            0.534625  \n3            0.540062  \n4            1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_with_all</th>\n      <th>run_with_none</th>\n      <th>run_with_no_phrasing</th>\n      <th>run_with_no_lemmatize</th>\n      <th>run_with_no_postag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>0.535477</td>\n      <td>0.619525</td>\n      <td>0.613201</td>\n      <td>0.550287</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.535477</td>\n      <td>1.000000</td>\n      <td>0.540951</td>\n      <td>0.536786</td>\n      <td>0.545302</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.619525</td>\n      <td>0.540951</td>\n      <td>1.000000</td>\n      <td>0.581408</td>\n      <td>0.534625</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.613201</td>\n      <td>0.536786</td>\n      <td>0.581408</td>\n      <td>1.000000</td>\n      <td>0.540062</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.550287</td>\n      <td>0.545302</td>\n      <td>0.534625</td>\n      <td>0.540062</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "## get correlations\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "import pandas as pd \n",
    "\n",
    "data = {}\n",
    "for run in ap_runs:\n",
    "    vals = []\n",
    "    for run2 in ap_runs:\n",
    "        vals.append(adjusted_mutual_info_score(run.labels, run2.labels))\n",
    "    data[run.name] = vals\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}